{
  "hash": "e6b7540e15c08007b53f23b153419a27",
  "result": {
    "markdown": "---\ntitle: \"Logistic Regression\"\n---\n\n\n\n\n## Logistic regression\n\n\n* When response variable is measured/counted, regression can work well.\n\n* But what if response is yes/no, lived/died, success/failure?\n\n* Model *probability* of success.\n\n* Probability must be between 0 and 1; need method that ensures this.\n\n* *Logistic regression* does this. In R, is a\n*generalized linear model* with binomial \"family\": \n\n\n::: {.cell}\n\n```{.r .cell-code}\nglm(y ~ x, family=\"binomial\")\n```\n:::\n\n\n\n\n* Begin with simplest case.\n\n\n\n## Packages\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(marginaleffects)\nlibrary(broom)\nlibrary(nnet)\nlibrary(conflicted)\nconflict_prefer(\"select\", \"dplyr\")\nconflict_prefer(\"filter\", \"dplyr\")\nconflict_prefer(\"rename\", \"dplyr\")\nconflict_prefer(\"summarize\", \"dplyr\")\n```\n:::\n\n\n\n   \n\n\n## The rats, part 1\n\n\n* Rats given dose of some poison; either live or die:\n\n\\small\n```\ndose status\n0 lived\n1 died\n2 lived\n3 lived\n4 died\n5 died\n```\n\n\\normalsize\n\n## Read in: \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rat.txt\"\nrats <- read_delim(my_url, \" \")\nrats\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 2\n   dose status\n  <dbl> <chr> \n1     0 lived \n2     1 died  \n3     2 lived \n4     3 lived \n5     4 died  \n6     5 died  \n```\n:::\n:::\n\n\n \n\n\n## Basic logistic regression\n\n\n* Make response into a factor first:\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrats2 <- rats %>% mutate(status = factor(status))\n```\n:::\n\n\n\\normalsize\n   \n\n\n* then fit model:\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstatus.1 <- glm(status ~ dose, family = \"binomial\", data = rats2)\n```\n:::\n\n\n\\normalsize\n   \n\n   \n\n\n## Output\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(status.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = status ~ dose, family = \"binomial\", data = rats2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)\n(Intercept)   1.6841     1.7979   0.937    0.349\ndose         -0.6736     0.6140  -1.097    0.273\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 8.3178  on 5  degrees of freedom\nResidual deviance: 6.7728  on 4  degrees of freedom\nAIC: 10.773\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\\normalsize\n\n\n## Interpreting the output\n\n\n* Like (multiple) regression, get\ntests of significance of individual $x$'s\n\n* Here not significant (only 6 observations).\n\n* \"Slope\" for dose is negative, meaning that as dose increases, probability of event modelled (survival) decreases.\n\n\n\n\n\n## Output part 2: predicted survival probs\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(status.1)) %>% \n  select(dose, estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  dose  estimate\n1    0 0.8434490\n2    1 0.7331122\n3    2 0.5834187\n4    3 0.4165813\n5    4 0.2668878\n6    5 0.1565510\n```\n:::\n:::\n\n\n\\normalsize \n\n## On a graph\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(status.1, condition = \"dose\")\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-1-1.pdf)\n:::\n:::\n\n\n\n\n## The rats, more\n\n\n* More realistic: more rats at each dose (say 10).\n\n* Listing each rat on one line makes a big data file.\n\n* Use format below: dose, number of survivals, number of deaths.\n\n```\n\ndose lived died\n0    10    0\n1     7    3 \n2     6    4 \n3     4    6 \n4     2    8 \n5     1    9  \n\n```\n\n\n* 6 lines of data correspond to 60 actual rats.\n\n* Saved in `rat2.txt`.\n\n\n\n## These data\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/rat2.txt\"\nrat2 <- read_delim(my_url, \" \")\nrat2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 3\n   dose lived  died\n  <dbl> <dbl> <dbl>\n1     0    10     0\n2     1     7     3\n3     2     6     4\n4     3     4     6\n5     4     2     8\n6     5     1     9\n```\n:::\n:::\n\n\n\\normalsize\n\n\n## Create response matrix:\n\n- Each row contains *multiple* observations.\n- Create *two-column* response:\n  - \\#survivals in first column, \n  - \\#deaths in second.\n\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresponse <- with(rat2, cbind(lived, died))\nresponse\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     lived died\n[1,]    10    0\n[2,]     7    3\n[3,]     6    4\n[4,]     4    6\n[5,]     2    8\n[6,]     1    9\n```\n:::\n:::\n\n\n\\normalsize\n\n- Response is R `matrix`:\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nclass(response)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"matrix\" \"array\" \n```\n:::\n:::\n\n\n\\normalsize\n\n     \n## Fit logistic regression\n\n- using response you just made:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrat2.1 <- glm(response ~ dose,\n  family = \"binomial\",\n  data = rat2\n)\n```\n:::\n\n\n\n\n\n\n## Output\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(rat2.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = response ~ dose, family = \"binomial\", data = rat2)\n\nCoefficients:\n            Estimate Std. Error z value Pr(>|z|)    \n(Intercept)   2.3619     0.6719   3.515 0.000439 ***\ndose         -0.9448     0.2351  -4.018 5.87e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 27.530  on 5  degrees of freedom\nResidual deviance:  2.474  on 4  degrees of freedom\nAIC: 18.94\n\nNumber of Fisher Scoring iterations: 4\n```\n:::\n:::\n\n\n\\normalsize\n\n\n## Predicted survival probs\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = rat2.1, dose = 0:5)\ncbind(predictions(rat2.1, newdata = new))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  rowid  estimate      p.value   s.value   conf.low conf.high dose\n1     1 0.9138762 0.0004389651 11.153606 0.73983042 0.9753671    0\n2     2 0.8048905 0.0031438277  8.313262 0.61695841 0.9135390    1\n3     3 0.6159474 0.1721141934  2.538562 0.44876099 0.7595916    2\n4     4 0.3840526 0.1721142946  2.538561 0.24040837 0.5512390    3\n5     5 0.1951095 0.0031438386  8.313257 0.08646093 0.3830417    4\n6     6 0.0861238 0.0004389668 11.153600 0.02463288 0.2601697    5\n```\n:::\n:::\n\n\n \n\n## On a picture\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(rat2.1, newdata = new)) %>% \n  select(estimate, conf.low, conf.high, dose) %>% \n  ggplot(aes(x = dose, y = estimate, \n             ymin = conf.low, ymax = conf.high)) + \n    geom_line() + geom_ribbon(alpha = 0.3)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-2-1.pdf)\n:::\n:::\n\n\n\n\n## Comments\n\n\n\n* Significant effect of dose. \n\n* Effect of larger dose is to *decrease* survival probability\n(\"slope\" negative; also see in decreasing predictions.)\n\n* Confidence intervals around prediction narrower (more data).\n\n## Multiple logistic regression\n\n\n* With more than one $x$, works much like multiple regression.\n\n* Example: study of patients with blood poisoning severe enough to warrant surgery. Relate survival to other potential risk factors.\n\n* Variables, 1=present, 0=absent:\n\n\n  * survival (death from sepsis=1), response\n  * shock\n  * malnutrition\n  * alcoholism\n  * age (as numerical variable)\n  * bowel infarction\n\n\n* See what relates to death.\n\n\n\n## Read in data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \n  \"http://ritsokiguess.site/datafiles/sepsis.txt\"\nsepsis <- read_delim(my_url, \" \")\n```\n:::\n\n\n \n## Make sure categoricals really are\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis %>% \n  mutate(across(-age, \\(x) factor(x))) -> sepsis\n```\n:::\n\n\n\n\n## The data (some)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 106 x 6\n   death shock malnut alcohol   age bowelinf\n   <fct> <fct> <fct>  <fct>   <dbl> <fct>   \n 1 0     0     0      0          56 0       \n 2 0     0     0      0          80 0       \n 3 0     0     0      0          61 0       \n 4 0     0     0      0          26 0       \n 5 0     0     0      0          53 0       \n 6 1     0     1      0          87 0       \n 7 0     0     0      0          21 0       \n 8 1     0     0      1          69 0       \n 9 0     0     0      0          57 0       \n10 0     0     1      0          76 0       \n# i 96 more rows\n```\n:::\n:::\n\n\n\n   \n\n\n## Fit model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.1 <- glm(death ~ shock + malnut + alcohol + age +\n  bowelinf,\nfamily = \"binomial\",\ndata = sepsis\n)\n```\n:::\n\n\n\n   \n\n\n## Output part 1\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(sepsis.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -9.75      2.54       -3.84 0.000124\n2 shock1        3.67      1.16        3.15 0.00161 \n3 malnut1       1.22      0.728       1.67 0.0948  \n4 alcohol1      3.35      0.982       3.42 0.000635\n5 age           0.0922    0.0303      3.04 0.00237 \n6 bowelinf1     2.80      1.16        2.40 0.0162  \n```\n:::\n:::\n\n\n \n\n\n\n* All P-values fairly small\n\n* but `malnut` not significant: remove.\n\n\n\n## Removing `malnut`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2 <- update(sepsis.1, . ~ . - malnut)\ntidy(sepsis.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -8.89      2.32       -3.84 0.000124\n2 shock1        3.70      1.10        3.35 0.000797\n3 alcohol1      3.19      0.917       3.47 0.000514\n4 age           0.0898    0.0292      3.07 0.00211 \n5 bowelinf1     2.39      1.07        2.23 0.0260  \n```\n:::\n:::\n\n\n \n\n\n\n* Everything significant now.\n\n\n\n## Comments\n\n\n* Most of the original $x$'s helped predict death. Only `malnut` seemed not to add anything.\n\n* Removed `malnut` and tried again.\n\n* Everything remaining is significant (though `bowelinf`\nactually became *less* significant).\n\n* All coefficients are *positive*, so having any of the risk\nfactors (or being older)\n*increases* risk of death.  \n\n\n## Predictions from model without \"malnut\"\n\n\n* A few (rows of original dataframe) chosen \"at random\":\n\n\\tiny\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis %>% slice(c(4, 1, 2, 11, 32)) -> new\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 6\n  death shock malnut alcohol   age bowelinf\n  <fct> <fct> <fct>  <fct>   <dbl> <fct>   \n1 0     0     0      0          26 0       \n2 0     0     0      0          56 0       \n3 0     0     0      0          80 0       \n4 1     0     0      1          66 1       \n5 1     0     0      1          49 0       \n```\n:::\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, conf.low, conf.high, shock:bowelinf)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     estimate     conf.low  conf.high shock malnut alcohol age bowelinf\n1 0.001415347 6.272642e-05 0.03103047     0      0       0  26        0\n2 0.020552383 4.102504e-03 0.09656596     0      0       0  56        0\n3 0.153416834 5.606838e-02 0.35603441     0      0       0  80        0\n4 0.931290137 5.490986e-01 0.99341482     0      0       1  66        1\n5 0.213000997 7.639063e-02 0.46967947     0      0       1  49        0\n```\n:::\n:::\n\n\n\\normalsize\n\n\n## Comments \n\n* Survival chances pretty good if no risk factors, though decreasing with age.\n\n* Having more than one risk factor reduces survival chances dramatically.\n\n* Usually good job of predicting survival; sometimes death predicted to survive.\n\n## Another way to assess effects\n\nof `age`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(model = sepsis.2, age = seq(30, 70, 10))\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  death shock alcohol bowelinf age\n1     0     0       0        0  30\n2     0     0       0        0  40\n3     0     0       0        0  50\n4     0     0       0        0  60\n5     0     0       0        0  70\n```\n:::\n:::\n\n\n\n\n## Assessing age effect \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, shock:age)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     estimate shock alcohol bowelinf age\n1 0.002026053     0       0        0  30\n2 0.004960283     0       0        0  40\n3 0.012092515     0       0        0  50\n4 0.029179226     0       0        0  60\n5 0.068729752     0       0        0  70\n```\n:::\n:::\n\n\n\n## Assessing shock effect\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(shock = c(0, 1), model = sepsis.2)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  death alcohol      age bowelinf shock\n1     0       0 51.28302        0     0\n2     0       0 51.28302        0     1\n```\n:::\n\n```{.r .cell-code}\ncbind(predictions(sepsis.2, newdata = new)) %>% \n  select(estimate, death:shock)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    estimate death alcohol      age bowelinf shock\n1 0.01354973     0       0 51.28302        0     0\n2 0.35742607     0       0 51.28302        0     1\n```\n:::\n:::\n\n\n\\normalsize\n\n## Assessing proportionality of odds for age\n\n\n* An assumption we made is that log-odds of survival depends\nlinearly on age.\n\n* Hard to get your head around, but \nbasic idea is that survival chances go continuously up (or down)\nwith age, instead of (for example) going up and then down.\n\n* In this case, seems reasonable, but should check:\n\n\n## Residuals vs.\\ age\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2 %>% augment(sepsis) %>% \n  ggplot(aes(x = age, y = .resid)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/virtusentella-1.pdf)\n:::\n:::\n\n\n \n## Comments\n\n* No apparent problems overall.\n\n* Confusing \"line\" across: no risk factors, survived. \n\n\n\n## Probability and odds\n\n* For probability $p$, odds is $p/(1-p)$:\n\n\n  \\begin{tabular}{rrrl}\n      \\hline\n      Prob.\\ & Odds & log-odds & in words\\\\\n      \\hline\n      0.5 & $0.5/0.5=1/1=1.00$ & $0.00$ &  ``even money''\\\\\n      0.1 & $0.1/0.9=1/9=0.11$ & $-2.20$ & ``9 to 1''\\\\\n      0.4 & $0.4/0.6=1/1.5=0.67$ & $-0.41$ & ``1.5 to 1''\\\\\n      0.8 & $0.8/0.2=4/1=4.00$ & $1.39$ & ``4 to 1 on''\\\\\n      \\hline\n    \\end{tabular}\n\n\n* Gamblers use odds: if you win at 9 to 1 odds, get original\nstake back plus 9 times the stake.\n\n* Probability has to be between 0 and 1\n\n* Odds between 0 and infinity\n\n* *Log*-odds can be anything: any log-odds corresponds to\nvalid probability.\n\n\n\n## Odds ratio\n\n\n* Suppose 90 of 100 men drank wine last week, but only 20 of 100 women.\n\n* Prob of man drinking wine $90/100=0.9$, woman $20/100=0.2$.\n\n* Odds of man drinking wine $0.9/0.1=9$, woman $0.2/0.8=0.25$.\n\n* Ratio of odds is $9/0.25=36$.\n\n* Way of quantifying difference between men and women: ``odds of\ndrinking wine 36 times larger for males than females''. \n\n\n\n## Sepsis data again\n\n\n* Recall prediction of probability of death from risk factors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2.tidy <- tidy(sepsis.2)\nsepsis.2.tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 5\n  term        estimate std.error statistic  p.value\n  <chr>          <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)  -8.89      2.32       -3.84 0.000124\n2 shock1        3.70      1.10        3.35 0.000797\n3 alcohol1      3.19      0.917       3.47 0.000514\n4 age           0.0898    0.0292      3.07 0.00211 \n5 bowelinf1     2.39      1.07        2.23 0.0260  \n```\n:::\n:::\n\n\n\n     \n\n\n* Slopes in column `estimate`.\n\n\n\n## Multiplying the odds\n\n\n* Can interpret slopes by taking \"exp\" of them. We ignore intercept.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsepsis.2.tidy %>% \n  mutate(exp_coeff=exp(estimate)) %>% \n  select(term, exp_coeff)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  term        exp_coeff\n  <chr>           <dbl>\n1 (Intercept)  0.000137\n2 shock1      40.5     \n3 alcohol1    24.2     \n4 age          1.09    \n5 bowelinf1   10.9     \n```\n:::\n:::\n\n\n\n## Interpretation\n\n\\small\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 2\n  term        exp_coeff\n  <chr>           <dbl>\n1 (Intercept)  0.000137\n2 shock1      40.5     \n3 alcohol1    24.2     \n4 age          1.09    \n5 bowelinf1   10.9     \n```\n:::\n:::\n\n\n\\normalsize\n\n\n* These say \"how much do you *multiply* odds of death by\nfor increase of 1 in corresponding risk factor?\" Or, what is odds\nratio for that factor being 1 (present) vs.\\ 0 (absent)?\n\n* Eg.\\ being alcoholic vs.\\ not increases odds of death by 24 times\n\n* One year older multiplies odds by about 1.1 times. Over 40 years,\nabout  $1.09^{40}=31$ times. \n\n\n\n## Odds ratio and relative risk\n\n\n* **Relative risk** is ratio of probabilities.\n\n* Above: 90 of 100 men (0.9) drank wine, 20 of 100 women (0.2).\n\n* Relative risk 0.9/0.2=4.5. (odds ratio was 36).\n\n* When probabilities small, relative risk and odds ratio similar.\n\n* Eg.\\ prob of man having disease 0.02, woman 0.01.\n\n* Relative risk $0.02/0.01=2$.\n\n## Odds ratio vs.\\ relative risk\n\n- Odds for men and for women:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n(od1 <- 0.02 / 0.98) # men\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.02040816\n```\n:::\n\n```{.r .cell-code}\n(od2 <- 0.01 / 0.99) # women\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.01010101\n```\n:::\n:::\n\n\n\n-  Odds ratio \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nod1 / od2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.020408\n```\n:::\n:::\n\n\n\n\n- Very close to relative risk of 2.\n\n\n## More than 2 response categories\n\n\n* With 2 response categories, model the probability of one, and prob of other is one minus that. So doesn't matter which category you model.\n\n* With more than 2 categories, have to think more carefully about the categories: are they\n\n\n* *ordered*: you can put them in a natural order (like low, medium, high)\n\n* *nominal*: ordering the categories doesn't make sense (like red, green, blue).\n\n\n* R handles both kinds of response; learn how.\n\n\n\n## Ordinal response: the miners\n\n\n* \nModel probability of being in given category *or lower*.\n\n* Example: coal-miners often suffer disease pneumoconiosis. Likelihood of disease believed to be greater \namong miners who have worked longer. \n\n* Severity of disease measured on categorical scale: none,\nmoderate, severe.\n\n## Miners data\n\n* Data are frequencies:\n\n```\nExposure None Moderate Severe\n5.8       98      0       0\n15.0      51      2       1\n21.5      34      6       3\n27.5      35      5       8\n33.5      32     10       9\n39.5      23      7       8\n46.0      12      6      10\n51.5       4      2       5\n```\n\n\n\n\n## Reading the data\n\nData in aligned columns with more than one space between, so: \n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/miners-tab.txt\"\nfreqs <- read_table(my_url)\n```\n:::\n\n\n\\normalsize\n\n\n## The data\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 4\n  Exposure  None Moderate Severe\n     <dbl> <dbl>    <dbl>  <dbl>\n1      5.8    98        0      0\n2     15      51        2      1\n3     21.5    34        6      3\n4     27.5    35        5      8\n5     33.5    32       10      9\n6     39.5    23        7      8\n7     46      12        6     10\n8     51.5     4        2      5\n```\n:::\n:::\n\n\n\n   \n\n\n## Tidying \n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs %>%\n  pivot_longer(-Exposure, names_to = \"Severity\", values_to = \"Freq\") %>%\n  mutate(Severity = fct_inorder(Severity)) -> miners\n```\n:::\n\n\n\n   \n\n\n## Result\n\n\\tiny\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 x 3\n   Exposure Severity  Freq\n      <dbl> <fct>    <dbl>\n 1      5.8 None        98\n 2      5.8 Moderate     0\n 3      5.8 Severe       0\n 4     15   None        51\n 5     15   Moderate     2\n 6     15   Severe       1\n 7     21.5 None        34\n 8     21.5 Moderate     6\n 9     21.5 Severe       3\n10     27.5 None        35\n# i 14 more rows\n```\n:::\n:::\n\n\n\\normalsize\n     \n\n\n## Plot proportions against exposure\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers %>% \n  group_by(Exposure) %>% \n  mutate(proportion = Freq / sum(Freq)) -> prop\nggplot(prop, aes(x = Exposure, y = proportion,\n                   colour = Severity)) + \n  geom_point() + geom_smooth(se = F)\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/bLogistic-28-1.pdf)\n:::\n:::\n\n\n\\normalsize\n\n\n## Reminder of data setup\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nminers\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 24 x 3\n   Exposure Severity  Freq\n      <dbl> <fct>    <dbl>\n 1      5.8 None        98\n 2      5.8 Moderate     0\n 3      5.8 Severe       0\n 4     15   None        51\n 5     15   Moderate     2\n 6     15   Severe       1\n 7     21.5 None        34\n 8     21.5 Moderate     6\n 9     21.5 Severe       3\n10     27.5 None        35\n# i 14 more rows\n```\n:::\n:::\n\n\n\n   \n\\normalsize\n\n\n\n## Fitting ordered logistic model\n\nUse function `polr` from package `MASS`. Like `glm`.\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.1 <- polr(Severity ~ Exposure,\n  weights = Freq,\n  data = miners\n)\n```\n:::\n\n\n \n\n\n## Output: not very illuminating\n\n\n\\scriptsize\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.1 <- polr(Severity ~ Exposure,\n  weights = Freq,\n  data = miners,\n  Hess = TRUE\n)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(sev.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\npolr(formula = Severity ~ Exposure, data = miners, weights = Freq, \n    Hess = TRUE)\n\nCoefficients:\n          Value Std. Error t value\nExposure 0.0959    0.01194   8.034\n\nIntercepts:\n                Value   Std. Error t value\nNone|Moderate    3.9558  0.4097     9.6558\nModerate|Severe  4.8690  0.4411    11.0383\n\nResidual Deviance: 416.9188 \nAIC: 422.9188 \n```\n:::\n:::\n\n\n\\normalsize\n   \n\n## Does exposure have an effect?\nFit model without `Exposure`, and compare\nusing `anova`. Note `1` for model with just intercept:\n\n\n\n::: {.cell}\n\n:::\n\n\n\n \n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsev.0 <- polr(Severity ~ 1, weights = Freq, data = miners)\nanova(sev.0, sev.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio tests of ordinal regression models\n\nResponse: Severity\n     Model Resid. df Resid. Dev   Test    Df LR stat.\n1        1       369   505.1621                      \n2 Exposure       368   416.9188 1 vs 2     1 88.24324\n  Pr(Chi)\n1        \n2       0\n```\n:::\n:::\n\n\n\\normalsize\n\nExposure definitely has effect on severity of disease. \n\n\n## Another way\n\n\n* What (if anything) can we drop from model with `exposure`?\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(sev.1, test = \"Chisq\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nSingle term deletions\n\nModel:\nSeverity ~ Exposure\n         Df    AIC    LRT  Pr(>Chi)    \n<none>      422.92                     \nExposure  1 509.16 88.243 < 2.2e-16 ***\n---\nSignif. codes:  \n0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n\n     \n\n\n* Nothing. Exposure definitely has effect.\n\n\n\n## Predicted probabilities 1/2\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfreqs %>% select(Exposure) -> new\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 1\n  Exposure\n     <dbl>\n1      5.8\n2     15  \n3     21.5\n4     27.5\n5     33.5\n6     39.5\n7     46  \n8     51.5\n```\n:::\n:::\n\n\n\n\n## Predicted probabilities 2/2\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(sev.1, newdata = new)) %>%\n  select(group, estimate, Exposure) %>% \n  pivot_wider(names_from = group, values_from = estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 8 x 4\n  Exposure  None Moderate Severe\n     <dbl> <dbl>    <dbl>  <dbl>\n1      5.8 0.968   0.0191 0.0132\n2     15   0.925   0.0433 0.0314\n3     21.5 0.869   0.0739 0.0569\n4     27.5 0.789   0.114  0.0969\n5     33.5 0.678   0.162  0.160 \n6     39.5 0.542   0.205  0.253 \n7     46   0.388   0.224  0.388 \n8     51.5 0.272   0.210  0.517 \n```\n:::\n:::\n\n\n\\normalsize\n\n## Plot of predicted probabilities\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(model = sev.1, condition = c(\"Exposure\", \"group\"),\n         type = \"probs\") +\n  geom_point(data = prop, aes(x = Exposure, y = proportion, \n                              colour = Severity)) -> ggg\n```\n:::\n\n\n\n## The graph\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggg\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-11-1.pdf)\n:::\n:::\n\n\n\n\n## Comments\n\n\n* Model appears to match data well enough.\n\n- As exposure goes up, prob of None\ngoes down, Severe goes up (sharply for high exposure).\n\n- So more exposure means worse disease.\n\n\n## Unordered responses\n\n\n* With unordered (nominal) responses, can use *generalized logit*.\n\n* Example: 735 people, record age and sex (male 0, female 1), which of 3 brands of some product preferred.\n\n* Data in `mlogit.csv` separated by commas (so\n`read_csv` will work):\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/mlogit.csv\"\nbrandpref <- read_csv(my_url)\n```\n:::\n\n\n \n\n\n\n\n## The data (some)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 735 x 3\n   brand   sex   age\n   <dbl> <dbl> <dbl>\n 1     1     0    24\n 2     1     0    26\n 3     1     0    26\n 4     1     1    27\n 5     1     1    27\n 6     3     1    27\n 7     1     0    27\n 8     1     0    27\n 9     1     1    27\n10     1     0    27\n# i 725 more rows\n```\n:::\n:::\n\n\n\n   \n\n\n## Bashing into shape\n\n\n* `sex` and `brand` not meaningful as numbers, so\nturn into factors:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref %>%\n  mutate(sex = ifelse(sex == 1, \"female\", \"male\"), \n         sex = factor(sex),\n         brand = factor(brand)\n         ) -> brandpref\n```\n:::\n\n\n \n \n## Fitting model \n\n* We use `multinom` from package `nnet`. Works\nlike `polr`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrands.1 <- multinom(brand ~ age + sex, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  12 (6 variable)\ninitial  value 807.480032 \niter  10 value 702.990572\nfinal  value 702.970704 \nconverged\n```\n:::\n:::\n\n\n \n\n\n## Can we drop anything?\n\n\n* Unfortunately `drop1` seems not to work:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndrop1(brands.1, test = \"Chisq\", trace = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntrying - age \n```\n:::\n\n::: {.cell-output .cell-output-error}\n```\nError in if (trace) {: argument is not interpretable as logical\n```\n:::\n:::\n\n\n\n* So, fall back on fitting model without what you want to test, and\ncomparing using `anova`.    \n\n\n\n## Do age/sex help predict brand? 1/3\n\nFit models without each of age and sex:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrands.2 <- multinom(brand ~ age, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  9 (4 variable)\ninitial  value 807.480032 \niter  10 value 706.796323\niter  10 value 706.796322\nfinal  value 706.796322 \nconverged\n```\n:::\n\n```{.r .cell-code}\nbrands.3 <- multinom(brand ~ sex, data = brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  9 (4 variable)\ninitial  value 807.480032 \nfinal  value 791.861266 \nconverged\n```\n:::\n:::\n\n\n \n\n\n## Do age/sex help predict brand? 2/3\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(brands.2, brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       age      1466   1413.593                      \n2 age + sex      1464   1405.941 1 vs 2     2 7.651236\n     Pr(Chi)\n1           \n2 0.02180496\n```\n:::\n\n```{.r .cell-code}\nanova(brands.3, brands.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       sex      1466   1583.723                      \n2 age + sex      1464   1405.941 1 vs 2     2 177.7811\n  Pr(Chi)\n1        \n2       0\n```\n:::\n:::\n\n\n\\normalsize\n\n\n## Do age/sex help predict brand? 3/3\n\n\n* `age` definitely significant (second `anova`)\n\n* `sex` significant also (first `anova`), though P-value less dramatic\n\n* Keep both.\n- Expect to see a large effect of `age`, and a smaller one of `sex`.\n\n\n\n\n## Another way to build model\n\n\n* Start from model with everything and run `step`:\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(brands.1, trace = 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\ntrying - age \ntrying - sex \n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\nmultinom(formula = brand ~ age + sex)\n\nCoefficients:\n  (Intercept)       age    sexmale\n2   -11.25127 0.3682202 -0.5237736\n3   -22.25571 0.6859149 -0.4658215\n\nResidual Deviance: 1405.941 \nAIC: 1417.941 \n```\n:::\n:::\n\n\n\\normalsize\n     \n\n* Final model contains both `age` and `sex` so neither\ncould be removed.\n\n\n## Making predictions\n\nFind age 5-number summary, and the two sexes:\n\n\\small\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(brandpref)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n brand       sex           age      \n 1:207   female:466   Min.   :24.0  \n 2:307   male  :269   1st Qu.:32.0  \n 3:221                Median :32.0  \n                      Mean   :32.9  \n                      3rd Qu.:34.0  \n                      Max.   :38.0  \n```\n:::\n:::\n\n\n\nSpace the ages out a bit for prediction (see over).\n\n\\normalsize\n\n## Combinations\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nnew <- datagrid(age = c(24, 30, 33, 35, 38), \n                sex = c(\"female\", \"male\"), model = brands.1)\nnew\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   brand age    sex\n1      2  24 female\n2      2  24   male\n3      2  30 female\n4      2  30   male\n5      2  33 female\n6      2  33   male\n7      2  35 female\n8      2  35   male\n9      2  38 female\n10     2  38   male\n```\n:::\n:::\n\n\n\n## The predictions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncbind(predictions(brands.1, newdata = new)) %>%\n  select(group, estimate, age, sex) %>% \n  pivot_wider(names_from = group, values_from = estimate)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 5\n     age sex       `1`    `2`     `3`\n   <dbl> <fct>   <dbl>  <dbl>   <dbl>\n 1    24 female 0.915  0.0819 0.00279\n 2    24 male   0.948  0.0502 0.00181\n 3    30 female 0.500  0.407  0.0933 \n 4    30 male   0.625  0.302  0.0732 \n 5    33 female 0.203  0.500  0.297  \n 6    33 male   0.296  0.432  0.272  \n 7    35 female 0.0840 0.432  0.484  \n 8    35 male   0.131  0.397  0.472  \n 9    38 female 0.0162 0.252  0.732  \n10    38 male   0.0260 0.239  0.735  \n```\n:::\n:::\n\n\n\n## Comments\n\n* Young males prefer brand 1, \nbut older males prefer brand 3.\n\n* Females similar, but like brand 1 less and\nbrand 2 more.\n\n- A clear `brand` effect, but the `sex` effect is less clear. \n\n## Making a plot\n\n- `plot_predictions` doesn't quite work\n- so don't draw, edit, *then* make graph:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.1, condition = c(\"age\", \"brand\", \"sex\"), \n         type = \"probs\", draw = FALSE)  %>% \n  ggplot(aes(x = age, y = estimate, colour = group, \n             linetype = sex)) +\n  geom_line() -> g\n```\n:::\n\n\n\n## The graph\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-16-1.pdf)\n:::\n:::\n\n\n  \n\n## Digesting the plot\n\n\n* Brand vs.\\ age: younger people (of both genders) prefer brand\n1, but older people (of both genders) prefer brand 3. (Explains\nsignificant age effect.)\n\n* Brand vs.\\ sex: females (solid) like brand 1 less than males\n(dashed), like brand 2 more (for all ages). \n\n* Not much brand difference between genders (solid and dashed\nlines of same colours close), but enough to be significant.\n\n* Model didn't include interaction, so modelled effect of gender\non brand same for each age, modelled effect of age same for each\ngender. (See also later.) \n\n\n## Alternative data format\n\nSummarize all people of same brand preference, same sex, same age on one line of data file with frequency on end:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 735 x 3\n   brand sex      age\n   <fct> <fct>  <dbl>\n 1 1     male      24\n 2 1     male      26\n 3 1     male      26\n 4 1     female    27\n 5 1     female    27\n 6 3     female    27\n 7 1     male      27\n 8 1     male      27\n 9 1     female    27\n10 1     male      27\n# i 725 more rows\n```\n:::\n:::\n\n\n\n\n```\n1 0 24 1\n1 0 26 2\n1 0 27 4\n1 0 28 4\n1 0 29 7\n1 0 30 3\n...\n```\n\nWhole data set in 65 lines not 735! But how?\n\n\n## Getting alternative data format\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrandpref %>%\n  group_by(age, sex, brand) %>%\n  summarize(Freq = n()) %>%\n  ungroup() -> b\nb\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 65 x 4\n     age sex    brand  Freq\n   <dbl> <fct>  <fct> <int>\n 1    24 male   1         1\n 2    26 male   1         2\n 3    27 female 1         4\n 4    27 female 3         1\n 5    27 male   1         4\n 6    28 female 1         6\n 7    28 female 2         2\n 8    28 female 3         1\n 9    28 male   1         4\n10    28 male   3         2\n# i 55 more rows\n```\n:::\n:::\n\n\n\n   \n\n## Fitting models, almost the same\n\n\n* Just have to remember `weights` to incorporate\nfrequencies.\n\n* Otherwise `multinom` assumes you have just 1 obs\non each line!\n\n* Again turn (numerical) `sex` and `brand` into factors:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nb %>%\n  mutate(sex = factor(sex)) %>%\n  mutate(brand = factor(brand)) -> bf\nb.1 <- multinom(brand ~ age + sex, data = bf, weights = Freq)\nb.2 <- multinom(brand ~ age, data = bf, weights = Freq)\n```\n:::\n\n\n\\normalsize\n\n\n\n## P-value for `sex` identical\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(b.2, b.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n      Model Resid. df Resid. Dev   Test    Df LR stat.\n1       age       126   1413.593                      \n2 age + sex       124   1405.941 1 vs 2     2 7.651236\n     Pr(Chi)\n1           \n2 0.02180496\n```\n:::\n:::\n\n\n\\normalsize\n\nSame P-value as before, so we haven't changed anything important.\n\n\n\n\n## Trying interaction between age and gender\n\n\n\n::: {.cell}\n\n:::\n\n\n\n   \n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbrands.4 <- update(brands.1, . ~ . + age:sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# weights:  15 (8 variable)\ninitial  value 807.480032 \niter  10 value 703.191146\niter  20 value 702.572260\niter  30 value 702.570900\niter  30 value 702.570893\niter  30 value 702.570893\nfinal  value 702.570893 \nconverged\n```\n:::\n\n```{.r .cell-code}\nanova(brands.1, brands.4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nLikelihood ratio tests of Multinomial Models\n\nResponse: brand\n                Model Resid. df Resid. Dev   Test    Df\n1           age + sex      1464   1405.941             \n2 age + sex + age:sex      1462   1405.142 1 vs 2     2\n   LR stat.   Pr(Chi)\n1                    \n2 0.7996223 0.6704466\n```\n:::\n:::\n\n\n\n   \n\\normalsize\n\n* No evidence that effect of age on brand preference differs for\nthe two genders.\n\n## Make graph again\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot_predictions(brands.4, condition = c(\"age\", \"brand\", \"sex\"), \n         type = \"probs\", draw = FALSE)  %>% \n  ggplot(aes(x = age, y = estimate, colour = group, \n             linetype = sex)) +\n  geom_line() -> g4\n```\n:::\n\n\n\n\n## Not much difference in the graph\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng4\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-19-1.pdf)\n:::\n:::\n\n\n\n## Compare model without interaction\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](logistic_files/figure-beamer/unnamed-chunk-20-1.pdf)\n:::\n:::\n",
    "supporting": [
      "logistic_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}
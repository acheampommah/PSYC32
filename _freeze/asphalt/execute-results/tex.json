{
  "hash": "25e7e208e7eefbed7de9dbae587937fa",
  "result": {
    "markdown": "---\ntitle: \"Case study: asphalt\"\n---\n\n\n\n## The asphalt data\n- 31 asphalt pavements prepared under different conditions. How does\nquality of pavement depend on these?\n- Variables:\n  - `pct.a.surf` Percentage of asphalt in surface layer\n  - `pct.a.base` Percentage of asphalt in base layer\n  - `fines` Percentage of fines in surface layer\n  - `voids` Percentage of voids in surface layer\n  - `rut.depth` Change in rut depth per million vehicle passes\n  - `viscosity` Viscosity of asphalt\n  - `run` 2 data collection periods: 1 for run 1, 0 for run 2.\n- `rut.depth` response. Depends on other variables, how?\n\n## Packages for this section\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MASS)\nlibrary(tidyverse)\nlibrary(broom)\nlibrary(leaps)\n```\n:::\n\n\n\nMake sure to load `MASS` before `tidyverse` (for annoying technical reasons).\n\n## Getting set up \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_url <- \"http://ritsokiguess.site/datafiles/asphalt.txt\"\nasphalt <- read_delim(my_url, \" \")\n```\n:::\n\n\n\n- Quantitative variables with one response: multiple regression.\n- Some issues here that don’t come up in “simple” regression; handle as\nwe go. (STAB27/STAC67 ideas.)\n\n## The data (some)\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 31 x 7\n   pct.a.surf pct.a.base fines voids rut.depth viscosity   run\n        <dbl>      <dbl> <dbl> <dbl>     <dbl>     <dbl> <dbl>\n 1       4.68       4.87   8.4  4.92      6.75      2.8      1\n 2       5.19       4.5    6.5  4.56     13         1.4      1\n 3       4.82       4.73   7.9  5.32     14.8       1.4      1\n 4       4.85       4.76   8.3  4.86     12.6       3.3      1\n 5       4.86       4.95   8.4  3.78      8.25      1.7      1\n 6       5.16       4.45   7.4  4.40     10.7       2.9      1\n 7       4.82       5.05   6.8  4.87      7.28      3.7      1\n 8       4.86       4.7    8.6  4.83     12.7       1.7      1\n 9       4.78       4.84   6.7  4.86     12.6       0.92     1\n10       5.16       4.76   7.7  4.03     20.6       0.68     1\n# i 21 more rows\n```\n:::\n:::\n\n\n\n## Plotting response “rut depth” against everything else\n\nSame idea as for plotting separate predictions on one plot:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt %>%\n  pivot_longer(\n    -rut.depth,\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(x = x, y = rut.depth)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g\n```\n:::\n\n\n\n“collect all the x-variables together into one column called x, with another\ncolumn xname saying which x they were, then plot these x’s against\nrut.depth, a separate facet for each x-variable.”\n\nI saved this graph to plot later (on the next page).\n\n## The plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-5-1.pdf)\n:::\n:::\n\n\n\n## Interpreting the plots\n- One plot of rut depth against each of the six other variables.\n- Get rough idea of what’s going on.\n- Trends mostly weak.\n- `viscosity` has strong but non-linear trend.\n- `run` has effect but variability bigger when run is 1.\n- Weak but downward trend for `voids`.\n- Non-linearity of `rut.depth`-`viscosity` relationship should concern\nus.\n\n## Log of `viscosity`: more nearly linear?\n\n- Take this back to asphalt engineer: suggests log of `viscosity`:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(asphalt, aes(y = rut.depth, x = log(viscosity))) +\n  geom_point() + geom_smooth(se = F)\n```\n:::\n\n\n\n(plot overleaf)\n\n## Rut depth against log-viscosity\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-6-1.pdf)\n:::\n:::\n\n\n\n## Comments and next steps\n- Not very linear, but better than before.\n- In multiple regression, hard to guess which x’s affect response. So\ntypically start by predicting from everything else.\n- Model formula has response on left, squiggle, explanatories on right\njoined by plusses:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1 <- lm(rut.depth ~ pct.a.surf + pct.a.base + fines +\n  voids + log(viscosity) + run, data = asphalt)\n```\n:::\n\n\n\n## Regression output: `summary(rut.1)` or:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(rut.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 x 12\n  r.squared adj.r.squared sigma statistic     p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>       <dbl> <dbl>  <dbl> <dbl> <dbl>\n1     0.806         0.758  3.32      16.6 0.000000174     6  -77.3  171.  182.\n# i 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n\n```{.r .cell-code}\ntidy(rut.1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic p.value\n  <chr>             <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)     -13.0      26.2      -0.496 0.625  \n2 pct.a.surf        3.97      2.50      1.59  0.125  \n3 pct.a.base        1.26      3.97      0.318 0.753  \n4 fines             0.116     1.01      0.115 0.909  \n5 voids             0.589     1.32      0.445 0.660  \n6 log(viscosity)   -3.15      0.919    -3.43  0.00220\n7 run              -1.97      3.65     -0.539 0.595  \n```\n:::\n:::\n\n\n\\normalsize\n\n## Comments\n- R-squared 81%, not so bad. \n- P-value in `glance` asserts that something helping to predict\nrut.depth.\n- Table of coefficients says `log(viscosity)`.\n- But confused by clearly non-significant variables: remove those to get\nclearer picture of what is helpful.\n- Before we do anything, look at residual plots:\n  - (a) of residuals against fitted values (as usual)\n  - (b) of residuals against each explanatory.\n- Problem fixes:\n  - with (a): fix response variable; \n  - with some plots in (b): fix those explanatory variables.\n\n## Plot fitted values against residuals\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(rut.1, aes(x = .fitted, y = .resid)) + geom_point()\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-9-1.pdf)\n:::\n:::\n\n\n\n## Plotting residuals against $x$ variables\n- Problem here is that residuals are in the fitted model, and the\nobserved $x$-values are in the original data frame `asphalt`. \n- Package broom contains a function `augment` that combines these two\ntogether so that they can later be plotted: start with a model first, and then augment with a\ndata frame:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1 %>% augment(asphalt) -> rut.1a\n```\n:::\n\n\n\n\n## What does rut.1a contain?\n\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nnames(rut.1a)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] \"pct.a.surf\" \"pct.a.base\" \"fines\"      \"voids\"      \"rut.depth\" \n [6] \"viscosity\"  \"run\"        \".fitted\"    \".resid\"     \".hat\"      \n[11] \".sigma\"     \".cooksd\"    \".std.resid\"\n```\n:::\n:::\n\n\n\n- all the stuff in original data frame, plus:\n- quantities from regression (starting with a dot)\n\n\n## Plotting residuals against $x$-variables \n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.1a %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(x = x, y = .resid)) +\n  geom_point() + facet_wrap(~xname, scales = \"free\") -> g\n```\n:::\n\n\n\n## The plot\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-14-1.pdf)\n:::\n:::\n\n\n\n## Comments\n- There is serious curve in plot of residuals vs. fitted values. Suggests a\ntransformation of $y$. \n- The residuals-vs-$x$’s  plots don’t show any serious trends. Worst\nprobably that potential curve against log-viscosity.\n- Also, large positive residual, 10, that shows up on all plots. Perhaps\ntransformation of $y$ will help with this too.\n- If residual-fitted plot OK, but some residual-$x$ plots not, try\ntransforming those $x$’s, eg. by adding $x^2$ to help with curve.\n\n## Which transformation?\n- Best way: consult with person who brought you the data.\n- Can’t do that here!\n- No idea what transformation would be good.\n- Let data choose: “Box-Cox transformation”.\n- Scale is that of “ladder of powers”: power transformation, but 0 is\nlog.\n\n\n## Running Box-Cox\n\nFrom package `MASS`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboxcox(rut.depth ~ pct.a.surf + pct.a.base + fines + voids +\n  log(viscosity) + run, data = asphalt)\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-15-1.pdf)\n:::\n:::\n\n\n\n## Comments on Box-Cox plot\n- $\\lambda$ represents power to transform $y$ with.\n- Best single choice of transformation parameter $\\lambda$ is peak of curve,\nclose to 0.\n- Vertical dotted lines give CI for $\\lambda$, about (−0.05, 0.2).\n- $\\lambda = 0$ means “log”.\n- Narrowness of confidence interval mean that these not supported by\ndata:\n  - No transformation ($\\lambda = 1$)\n  - Square root ($\\lambda = 0.5$)\n  - Reciprocal ($\\lambda = −1$).\n\n## Relationships with explanatories\n- As before: plot response (now `log(rut.depth)`) against other\nexplanatory variables, all in one shot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nasphalt %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\"\n  ) %>%\n  ggplot(aes(y = log(rut.depth), x = x)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g3\n```\n:::\n\n\n\n## The new plots\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng3\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-17-1.pdf)\n:::\n:::\n\n\n\n## Modelling with transformed response\n- These trends look pretty straight, especially with `log.viscosity`.\n- Values of `log.rut.depth` for each `run` have same spread.\n- Other trends weak, but are straight if they exist.\n- Start modelling from the beginning again.\n- Model `log.rut.depth` in terms of everything else, see what can be\nremoved:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.2 <- lm(log(rut.depth) ~ pct.a.surf + pct.a.base +\n  fines + voids + log(viscosity) + run, data = asphalt)\n```\n:::\n\n\n\n- use `tidy` from `broom` to display just the coefficients.\n\n## Output\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)     -1.57      2.44      -0.646 0.525      \n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 pct.a.base      -0.103     0.369     -0.280 0.782      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 voids            0.199     0.123      1.62  0.119      \n6 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n7 run              0.340     0.339      1.00  0.326      \n```\n:::\n:::\n\n\n\n## Taking out everything non-significant\n- Try: remove everything but pct.a.surf and log.viscosity:\n\n\\footnotesize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.3 <- lm(log(rut.depth) ~ pct.a.surf + log(viscosity), data = asphalt)\n```\n:::\n\n\n\\normalsize\n\n\\footnotesize\n- Check that removing all those variables wasn’t too much:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(rut.3, rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nModel 1: log(rut.depth) ~ pct.a.surf + log(viscosity)\nModel 2: log(rut.depth) ~ pct.a.surf + pct.a.base + fines + voids + log(viscosity) + \n    run\n  Res.Df    RSS Df Sum of Sq      F Pr(>F)\n1     28 2.8809                           \n2     24 2.2888  4   0.59216 1.5523 0.2191\n```\n:::\n:::\n\n\n\\normalsize\n\n- $H_0$ : two models equally good; $H_a$ : bigger model better.\n- Null not rejected here; small model as good as the big one, so prefer\nsimpler smaller model `rut.3`.\n\n## Find the largest P-value by eye:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 (Intercept)     -1.57      2.44      -0.646 0.525      \n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 pct.a.base      -0.103     0.369     -0.280 0.782      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 voids            0.199     0.123      1.62  0.119      \n6 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n7 run              0.340     0.339      1.00  0.326      \n```\n:::\n:::\n\n\n\n- Largest P-value is 0.78 for `pct.a.base`, not significant.\n- So remove this first, re-fit and re-assess.\n- Or, as over.\n\n## Get the computer to find the largest P-value for you\n\n- Output from `tidy` is itself a data frame, thus:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.2) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 log(viscosity)  -0.558     0.0854    -6.53  0.000000945\n2 pct.a.surf       0.584     0.232      2.52  0.0190     \n3 voids            0.199     0.123      1.62  0.119      \n4 fines            0.0978    0.0941     1.04  0.309      \n5 run              0.340     0.339      1.00  0.326      \n6 (Intercept)     -1.57      2.44      -0.646 0.525      \n7 pct.a.base      -0.103     0.369     -0.280 0.782      \n```\n:::\n:::\n\n\n\n- Largest P-value at the bottom.\n\n## Take out `pct.a.base`\n\n- Copy and paste the `lm` code and remove what you're removing:\n\n\\small\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.4 <- lm(log(rut.depth) ~ pct.a.surf + fines + voids + \n              log(viscosity) + run, data = asphalt)\ntidy(rut.4) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 log(viscosity)  -0.552     0.0818     -6.75 0.000000448\n2 pct.a.surf       0.593     0.225       2.63 0.0143     \n3 voids            0.200     0.121       1.66 0.109      \n4 (Intercept)     -2.08      1.61       -1.29 0.208      \n5 run              0.360     0.325       1.11 0.279      \n6 fines            0.0889    0.0870      1.02 0.316      \n```\n:::\n:::\n\n\n\\normalsize\n\n- `fines` is next to go, P-value 0.32.\n\n## “Update”\n\nAnother way to do the same thing:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.4 <- update(rut.2, . ~ . - pct.a.base)\ntidy(rut.4) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 x 5\n  term           estimate std.error statistic     p.value\n  <chr>             <dbl>     <dbl>     <dbl>       <dbl>\n1 log(viscosity)  -0.552     0.0818     -6.75 0.000000448\n2 pct.a.surf       0.593     0.225       2.63 0.0143     \n3 voids            0.200     0.121       1.66 0.109      \n4 (Intercept)     -2.08      1.61       -1.29 0.208      \n5 run              0.360     0.325       1.11 0.279      \n6 fines            0.0889    0.0870      1.02 0.316      \n```\n:::\n:::\n\n\n\n- Again, `fines` is the one to go. (Output identical as it should be.)\n\n## Take out fines:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.5 <- update(rut.4, . ~ . - fines)\ntidy(rut.5) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 x 5\n  term           estimate std.error statistic      p.value\n  <chr>             <dbl>     <dbl>     <dbl>        <dbl>\n1 log(viscosity)   -0.580    0.0772    -7.52  0.0000000559\n2 pct.a.surf        0.548    0.221      2.48  0.0200      \n3 voids             0.232    0.117      1.99  0.0577      \n4 run               0.295    0.319      0.923 0.365       \n5 (Intercept)      -1.26     1.39      -0.902 0.375       \n```\n:::\n:::\n\n\n\nCan’t take out intercept, so `run`, with P-value 0.36, goes next.\n\n## Take out run:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrut.6 <- update(rut.5, . ~ . - run)\ntidy(rut.6) %>% arrange(p.value)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 log(viscosity)   -0.646    0.0288   -22.5   5.29e-19\n2 pct.a.surf        0.555    0.220      2.52  1.80e- 2\n3 voids             0.245    0.116      2.12  4.36e- 2\n4 (Intercept)      -1.02     1.36      -0.748 4.61e- 1\n```\n:::\n:::\n\n\n\nAgain, can’t take out intercept, so largest P-value is for `voids`, 0.044. But\nthis is significant, so we shouldn’t remove `voids`.\n\n## Comments\n- Here we stop: `pct.a.surf`, `voids` and `log.viscosity` would all\nmake fit significantly worse if removed. So they stay.\n- Different final result from taking things out one at a time (top), than\nby taking out 4 at once (bottom):\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoef(rut.6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   (Intercept)     pct.a.surf          voids log(viscosity) \n    -1.0207945      0.5554686      0.2447934     -0.6464911 \n```\n:::\n\n```{.r .cell-code}\ncoef(rut.3)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   (Intercept)     pct.a.surf log(viscosity) \n     0.9001389      0.3911481     -0.6185628 \n```\n:::\n:::\n\n\n\n- Point: Can make difference which way we go.\n\n## Comments on variable selection\n- Best way to decide which $x$’s belong: expert knowledge: which of\nthem should be important.\n- Best automatic method: what we did, “backward selection”.\n- Do not learn about “stepwise regression”! [**eg. here**](https://towardsdatascience.com/stopping-stepwise-why-stepwise-selection-is-bad-and-what-you-should-use-instead-90818b3f52df)\n- R has function `step` that does backward selection, like this:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(rut.2, direction = \"backward\", test = \"F\")\n```\n:::\n\n\n\nGets same answer as we did (by removing least significant x). \n\n- Removing non-significant $x$’s may remove interesting ones whose\nP-values happened not to reach 0.05. Consider using less stringent\ncutoff like 0.20 or even bigger.\n- Can also fit all possible regressions, as over (may need to do\n`install.packages(\"leaps\")` first).\n\n## All possible regressions (output over)\n\nUses package `leaps`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nleaps <- regsubsets(log(rut.depth) ~ pct.a.surf + \n                      pct.a.base + fines + voids + \n                      log(viscosity) + run, \n                    data = asphalt, nbest = 2)\ns <- summary(leaps)\nwith(s, data.frame(rsq, outmat)) -> d\n```\n:::\n\n\n\n## The output\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nd %>% rownames_to_column(\"model\") %>% arrange(desc(rsq))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      model       rsq pct.a.surf pct.a.base fines voids log.viscosity. run\n1  6  ( 1 ) 0.9609642          *          *     *     *              *   *\n2  5  ( 1 ) 0.9608365          *                *     *              *   *\n3  5  ( 2 ) 0.9593265          *          *     *     *              *    \n4  4  ( 1 ) 0.9591996          *                      *              *   *\n5  4  ( 2 ) 0.9589206          *                *     *              *    \n6  3  ( 1 ) 0.9578631          *                      *              *    \n7  3  ( 2 ) 0.9534561          *                *                    *    \n8  2  ( 1 ) 0.9508647          *                                     *    \n9  2  ( 2 ) 0.9479541                                 *              *    \n10 1  ( 1 ) 0.9452562                                                *    \n11 1  ( 2 ) 0.8624107                                                    *\n```\n:::\n:::\n\n\n\\normalsize\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\n## Comments\n- Problem: even adding a worthless x increases R-squared. So try for\nline where R-squared stops increasing “too much”, eg. top line (just\nlog.viscosity), first 3-variable line (backwards-elimination model).\nHard to judge.\n- One solution (STAC67): adjusted R-squared, where adding worthless\nvariable makes it go down.\n- `data.frame` rather than `tibble` because there are several columns in\n`outmat`. \n\n## All possible regressions, adjusted R-squared\n\n\n\n::: {.cell}\n\n:::\n\n\n\n\\scriptsize\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwith(s, data.frame(adjr2, outmat)) %>% \n  rownames_to_column(\"model\") %>% \n  arrange(desc(adjr2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      model     adjr2 pct.a.surf pct.a.base fines voids log.viscosity. run\n1  3  ( 1 ) 0.9531812          *                      *              *    \n2  5  ( 1 ) 0.9530038          *                *     *              *   *\n3  4  ( 1 ) 0.9529226          *                      *              *   *\n4  4  ( 2 ) 0.9526007          *                *     *              *    \n5  6  ( 1 ) 0.9512052          *          *     *     *              *   *\n6  5  ( 2 ) 0.9511918          *          *     *     *              *    \n7  3  ( 2 ) 0.9482845          *                *                    *    \n8  2  ( 1 ) 0.9473550          *                                     *    \n9  2  ( 2 ) 0.9442365                                 *              *    \n10 1  ( 1 ) 0.9433685                                                *    \n11 1  ( 2 ) 0.8576662                                                    *\n```\n:::\n:::\n\n\n\\normalsize\n\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## Revisiting the best model\n- Best model was our rut.6:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(rut.6)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 4 x 5\n  term           estimate std.error statistic  p.value\n  <chr>             <dbl>     <dbl>     <dbl>    <dbl>\n1 (Intercept)      -1.02     1.36      -0.748 4.61e- 1\n2 pct.a.surf        0.555    0.220      2.52  1.80e- 2\n3 voids             0.245    0.116      2.12  4.36e- 2\n4 log(viscosity)   -0.646    0.0288   -22.5   5.29e-19\n```\n:::\n:::\n\n\n\n## Revisiting (2)\n- Regression slopes say that rut depth increases as log-viscosity\ndecreases, `pct.a.surf` increases and `voids` increases. This more or\nless checks out with out scatterplots against `log.viscosity`. \n- We should check residual plots again, though previous scatterplots say\nit’s unlikely that there will be a problem:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng <- ggplot(rut.6, aes(y = .resid, x = .fitted)) + \ngeom_point()\n```\n:::\n\n\n\n## Residuals against fitted values\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-39-1.pdf)\n:::\n:::\n\n\n\n## Plotting residuals against x’s\n- Do our trick again to put them all on one plot:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\naugment(rut.6, asphalt) %>%\n  mutate(log_vis=log(viscosity)) %>% \n  pivot_longer(\n    c(pct.a.surf:voids, run, log_vis),\n    names_to=\"xname\", values_to=\"x\",\n  ) %>%\n  ggplot(aes(y = .resid, x = x)) + geom_point() +\n  facet_wrap(~xname, scales = \"free\") -> g2\n```\n:::\n\n\n\n## Residuals against the x’s\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ng2\n```\n\n::: {.cell-output-display}\n![](asphalt_files/figure-beamer/asphalt-41-1.pdf)\n:::\n:::\n\n\n\n## Comments\n- None of the plots show any sort of pattern. The points all look\nrandom on each plot.\n- On the plot of fitted values (and on the one of log.viscosity), the\npoints seem to form a “left half” and a “right half” with a gap in the\nmiddle. This is not a concern.\n- One of the pct.a.surf values is low outlier (4), shows up top left of\nthat plot.\n- Only two possible values of run; the points in each group look\nrandomly scattered around 0, with equal spreads.\n- Residuals seem to go above zero further than below, suggesting a\nmild non-normality, but not enough to be a problem.\n\n## Variable-selection strategies\n- Expert knowledge.\n- Backward elimination.\n- All possible regressions.\n- Taking a variety of models to experts and asking their opinion.\n- Use a looser cutoff to eliminate variables in backward elimination (eg.\nonly if P-value greater than 0.20).\n- If goal is prediction, eliminating worthless variables less important.\n- If goal is understanding, want to eliminate worthless variables where\npossible.\n- Results of variable selection not always reproducible, so caution\nadvised.\n\n",
    "supporting": [
      "asphalt_files/figure-beamer"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}